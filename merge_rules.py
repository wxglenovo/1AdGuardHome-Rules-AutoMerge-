#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import requests

URLS_FILE = "urls.txt"
TMP_DIR = "tmp"
DIST_DIR = "dist"
MERGED_FILE = os.path.join(DIST_DIR, "merged_rules.txt")
LOG_FILE = os.path.join(DIST_DIR, "log.txt")

os.makedirs(TMP_DIR, exist_ok=True)
os.makedirs(DIST_DIR, exist_ok=True)

def process_line(line):
    line = line.strip()
    log_msgs = []
    results = []

    if not line:
        return results, log_msgs

    # æ³¨é‡Šè¡Œ
    if line.startswith("!"):
        log_msgs.append(f"ğŸš« å»æ‰æ³¨é‡Šè¡Œ: {line}")
        return results, log_msgs

    # HOSTS è§„åˆ™è½¬æ¢
    if line.startswith("0.0.0.0") or line.startswith("127.0.0.1"):
        parts = line.split()
        if len(parts) >= 2:
            domain = parts[1]
            new_rule = f"|{domain}^"
            results.append(new_rule)
            log_msgs.append(f"âœ… HOSTS è½¬æ¢: {line} â†’ {new_rule}")
        return results, log_msgs

    # å¤šåŸŸåæ‹†åˆ†
    if ',' in line.split('##')[0] or ',' in line.split('#@#')[0] or ',' in line.split('#?#')[0]:
        sep = ''
        if '##' in line:
            sep = '##'
        elif '#@#' in line:
            sep = '#@#'
        elif '#?#' in line:
            sep = '#?#'

        domains_part, suffix = line.split(sep, 1)
        domains = domains_part.split(',')
        for d in domains:
            d = d.strip()
            if line.startswith('||'):
                new_rule = f"||{d}{sep}{suffix}"
            else:
                new_rule = f"|{d}{sep}{suffix}"
            results.append(new_rule)
            log_msgs.append(f"âœ… å¤šåŸŸåæ‹†åˆ†: {line} â†’ {new_rule}")
        return results, log_msgs

    # æ™®é€šè§„åˆ™ï¼Œä¸æ‰“å°æ—¥å¿—
    results.append(line)
    return results, log_msgs

merged_rules = []
log_lines = []

if not os.path.exists(URLS_FILE):
    print(f"âš  {URLS_FILE} ä¸å­˜åœ¨")
    exit(1)

with open(URLS_FILE, 'r', encoding='utf-8') as f:
    urls = [line.strip() for line in f if line.strip()]

for idx, url in enumerate(urls, start=1):
    print(f"ğŸ”— å¼€å§‹å¤„ç†ç¬¬ {idx}/{len(urls)} ä¸ªæº: {url}")
    try:
        r = requests.get(url, timeout=20)
        r.raise_for_status()
        lines = r.text.splitlines()
        processed = []
        for line in lines:
            results, logs = process_line(line)
            for log in logs:
                print(log)          # é€æ¡æ‰“å°æ—¥å¿—
                log_lines.append(log)
            processed.extend(results)
        # ä¿å­˜æ¯ä¸ªæºæ‹†åˆ†åçš„è§„åˆ™
        tmp_file = os.path.join(TMP_DIR, f"{idx:03}.txt")
        with open(tmp_file, 'w', encoding='utf-8') as ftmp:
            ftmp.write('\n'.join(processed))
        merged_rules.extend(processed)
    except Exception as e:
        print(f"âŒ ä¸‹è½½æˆ–å¤„ç†å¤±è´¥: {e}")

# ä¿å­˜åˆå¹¶åçš„è§„åˆ™
with open(MERGED_FILE, 'w', encoding='utf-8') as f:
    f.write('\n'.join(merged_rules))

# ä¿å­˜æ—¥å¿—
with open(LOG_FILE, 'w', encoding='utf-8') as f:
    f.write('\n'.join(log_lines))

print(f"ğŸ‰ å®Œæˆï¼å…±ç”Ÿæˆ {len(merged_rules)} æ¡è§„åˆ™")
print(f"ğŸ“‚ tmp/ æ–‡ä»¶: {len(os.listdir(TMP_DIR))} ä¸ª")
print(f"ğŸ“„ åˆå¹¶è§„åˆ™æ–‡ä»¶: {MERGED_FILE}")
print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {LOG_FILE}")
