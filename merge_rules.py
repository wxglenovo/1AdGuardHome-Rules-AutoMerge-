#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import requests

URLS_FILE = "urls.txt"
TMP_DIR = "tmp"
DIST_DIR = "dist"
MERGED_FILE = os.path.join(DIST_DIR, "merged_rules.txt")
LOG_FILE = os.path.join(DIST_DIR, "log.txt")

os.makedirs(TMP_DIR, exist_ok=True)
os.makedirs(DIST_DIR, exist_ok=True)

def process_line(line):
    line = line.strip()
    log_msgs = []
    results = []

    if not line:
        return results, log_msgs

    # å»æ‰æ³¨é‡Šè¡Œ
    if line.startswith("!"):
        log_msgs.append(f"ğŸš« å»æ‰æ³¨é‡Šè¡Œ: {line}")
        return results, log_msgs

    # HOSTS è½¬æ¢
    if line.startswith("0.0.0.0") or line.startswith("127.0.0.1"):
        parts = line.split()
        if len(parts) >= 2:
            hosts = parts[1].split(",")  # å¤šåŸŸåé€—å·æ‹†åˆ†
            for host in hosts:
                host = host.strip()
                if host:
                    converted = f"||{host}^"
                    results.append(converted)
                    log_msgs.append(f"âœ… HOSTS è½¬æ¢: {line} â†’ {converted}")
        else:
            log_msgs.append(f"âš  HOSTS æ ¼å¼é”™è¯¯ï¼Œå¿½ç•¥: {line}")
        return results, log_msgs

    # å¤šåŸŸåæ‹†åˆ†è§„åˆ™
    if "," in line:
        sep = ''
        if '##' in line:
            sep = '##'
        elif '#@#' in line:
            sep = '#@#'
        elif '#?#' in line:
            sep = '#?#'

        if sep:
            domains_part, suffix = line.split(sep, 1)
            domains = [d.strip() for d in domains_part.split(",") if d.strip()]
            for domain in domains:
                new_rule = f"||{domain}{sep}{suffix}"
                results.append(new_rule)
                log_msgs.append(f"âœ… å¤šåŸŸåæ‹†åˆ†: {line} â†’ {new_rule}")
        else:
            # æ™®é€šé€—å·è§„åˆ™
            domains = [d.strip() for d in line.split(",") if d.strip()]
            for domain in domains:
                new_rule = f"||{domain}^"
                results.append(new_rule)
                log_msgs.append(f"âœ… å¤šåŸŸåæ‹†åˆ†: {line} â†’ {new_rule}")
        return results, log_msgs

    # æ™®é€šè§„åˆ™ï¼Œä¸æ‰“å°æ—¥å¿—
    results.append(line)
    return results, log_msgs

def main():
    merged_rules = []
    log_lines = []

    if not os.path.exists(URLS_FILE):
        print(f"âš  {URLS_FILE} ä¸å­˜åœ¨")
        return

    with open(URLS_FILE, 'r', encoding='utf-8') as f:
        urls = [line.strip() for line in f if line.strip()]

    for idx, url in enumerate(urls, start=1):
        print(f"ğŸ”— å¼€å§‹å¤„ç†ç¬¬ {idx}/{len(urls)} ä¸ªæº: {url}")
        try:
            r = requests.get(url, timeout=20)
            r.raise_for_status()
            lines = r.text.splitlines()
            processed = []
            for line in lines:
                results, logs = process_line(line)
                for log in logs:
                    print(log)         # ä¸­æ–‡é€æ¡æ‰“å°æ—¥å¿—
                    log_lines.append(log)
                processed.extend(results)
            # ä¿å­˜æ¯ä¸ªæºæ‹†åˆ†åçš„è§„åˆ™
            tmp_file = os.path.join(TMP_DIR, f"{idx:03}.txt")
            with open(tmp_file, 'w', encoding='utf-8') as ftmp:
                ftmp.write('\n'.join(processed))
            merged_rules.extend(processed)
        except Exception as e:
            print(f"âŒ ä¸‹è½½æˆ–å¤„ç†å¤±è´¥: {e}")

    # ä¿å­˜åˆå¹¶åçš„è§„åˆ™
    with open(MERGED_FILE, 'w', encoding='utf-8') as f:
        f.write('\n'.join(merged_rules))

    # ä¿å­˜æ—¥å¿—
    with open(LOG_FILE, 'w', encoding='utf-8') as f:
        f.write('\n'.join(log_lines))

    print(f"ğŸ‰ å®Œæˆï¼å…±ç”Ÿæˆ {len(merged_rules)} æ¡è§„åˆ™")
    print(f"ğŸ“‚ tmp/ æ–‡ä»¶: {len(os.listdir(TMP_DIR))} ä¸ª")
    print(f"ğŸ“„ åˆå¹¶è§„åˆ™æ–‡ä»¶: {MERGED_FILE}")
    print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {LOG_FILE}")

if __name__ == "__main__":
    main()
