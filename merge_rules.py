#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import requests

URLS_FILE = "urls.txt"
TMP_DIR = "tmp"
DIST_DIR = "dist"
MERGED_FILE = os.path.join(DIST_DIR, "merged_rules.txt")
LOG_FILE = os.path.join(DIST_DIR, "log.txt")

os.makedirs(TMP_DIR, exist_ok=True)
os.makedirs(DIST_DIR, exist_ok=True)

log_lines = []

# ------------------------------
# åˆ é™¤ tmp/ ä¸­æ‰€æœ‰ä»¥ # å¼€å¤´çš„æ–‡ä»¶å¹¶æ‰“å°æ—¥å¿—
# ------------------------------
for fname in os.listdir(TMP_DIR):
    if fname.startswith("#"):
        fpath = os.path.join(TMP_DIR, fname)
        try:
            os.remove(fpath)
            log_msg = f"ğŸ—‘ åˆ é™¤æ³¨é‡Šæ–‡ä»¶: {fpath}"
            print(log_msg)
            log_lines.append(log_msg)
        except Exception as e:
            log_msg = f"âŒ åˆ é™¤æ–‡ä»¶å¤±è´¥: {fpath} -> {e}"
            print(log_msg)
            log_lines.append(log_msg)

def process_line(line):
    line = line.strip()
    line_logs = []
    results = []

    if not line:
        return results, line_logs

    # æ³¨é‡Šè¡Œå¤„ç†: è®°å½•æ—¥å¿—
    if line.startswith("!") or line.startswith("#"):
        line_logs.append(f"ğŸš« å»æ‰æ³¨é‡Šè¡Œ: {line}")
        return results, line_logs

    # HOSTS è§„åˆ™è½¬æ¢
    if line.startswith("0.0.0.0") or line.startswith("127.0.0.1"):
        parts = line.split()
        if len(parts) >= 2:
            domain = parts[1]
            new_rule = f"|{domain}^"
            results.append(new_rule)
            line_logs.append(f"âœ… HOSTS è½¬æ¢: {line} â†’ {new_rule}")
        return results, line_logs

    # å¤šåŸŸåæ‹†åˆ†é€»è¾‘
    sep = ''
    if '##' in line:
        sep = '##'
    elif '#@#' in line:
        sep = '#@#'
    elif '#?#' in line:
        sep = '#?#'

    if sep and ',' in line.split(sep)[0]:
        domains_part, suffix = line.split(sep, 1)
        prefix = ''
        if domains_part.startswith('||'):
            prefix = '||'
            domains_part = domains_part[2:]
        elif domains_part.startswith('|'):
            prefix = '|'
            domains_part = domains_part[1:]
        else:
            prefix = '|'
        domains = [d.strip() for d in domains_part.split(',')]
        new_rules = [f"{prefix}{d}{sep}{suffix}" for d in domains]
        results.extend(new_rules)
        line_logs.append(f"âœ… å¤šåŸŸåæ‹†åˆ†: {line}")
        for r in new_rules:
            line_logs.append(f"    â†’ {r}")
        return results, line_logs

    # æ™®é€šè§„åˆ™ï¼Œä¸æ‰“å°æ—¥å¿—
    results.append(line)
    return results, line_logs

merged_rules = []

if not os.path.exists(URLS_FILE):
    print(f"âš  {URLS_FILE} ä¸å­˜åœ¨")
    exit(1)

with open(URLS_FILE, 'r', encoding='utf-8') as f:
    urls = [line.strip() for line in f if line.strip()]

for idx, url in enumerate(urls, start=1):
    print(f"ğŸ”— å¼€å§‹å¤„ç†ç¬¬ {idx}/{len(urls)} ä¸ªæº: {url}")
    try:
        r = requests.get(url, timeout=20)
        r.raise_for_status()
        lines = r.text.splitlines()
        processed = []
        for line in lines:
            results, logs = process_line(line)
            for log in logs:
                print(log)          # é€æ¡æ‰“å°æ—¥å¿—
                log_lines.append(log)
            processed.extend(results)
        # ä¿å­˜æ¯ä¸ªæºæ‹†åˆ†åçš„è§„åˆ™
        tmp_file = os.path.join(TMP_DIR, f"{idx:03}.txt")
        with open(tmp_file, 'w', encoding='utf-8') as ftmp:
            ftmp.write('\n'.join(processed))
        merged_rules.extend(processed)
    except Exception as e:
        log_msg = f"âŒ ä¸‹è½½æˆ–å¤„ç†å¤±è´¥: {e}"
        print(log_msg)
        log_lines.append(log_msg)

# ä¿å­˜åˆå¹¶åçš„è§„åˆ™
with open(MERGED_FILE, 'w', encoding='utf-8') as f:
    f.write('\n'.join(merged_rules))

# ä¿å­˜æ—¥å¿—
with open(LOG_FILE, 'w', encoding='utf-8') as f:
    f.write('\n'.join(log_lines))

print(f"ğŸ‰ å®Œæˆï¼å…±ç”Ÿæˆ {len(merged_rules)} æ¡è§„åˆ™")
print(f"ğŸ“‚ tmp/ æ–‡ä»¶: {len(os.listdir(TMP_DIR))} ä¸ª")
print(f"ğŸ“„ åˆå¹¶è§„åˆ™æ–‡ä»¶: {MERGED_FILE}")
print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {LOG_FILE}")
